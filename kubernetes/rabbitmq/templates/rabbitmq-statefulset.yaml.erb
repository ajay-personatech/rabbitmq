apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: rabbitmq
  namespace: <%= bindings["namespace"] %>
  labels:
    app: rabbitmq
spec:
  serviceName: rabbitmq-headless # Must match the headless service name
  replicas: <%= bindings["rabbitmq_base_replicas"] || 3 %>
  selector:
    matchLabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
    spec:
      # Ensure pods run on different nodes for HA, if possible and desired
      # affinity:
      #   podAntiAffinity:
      #     preferredDuringSchedulingIgnoredDuringExecution:
      #     - weight: 100
      #       podAffinityTerm:
      #         labelSelector:
      #           matchExpressions:
      #           - key: app
      #             operator: In
      #             values:
      #             - rabbitmq
      #         topologyKey: "kubernetes.io/hostname"

      # Using Workload Identity for GCP Secret Manager (recommended)
      # Replace YOUR_GCP_SERVICE_ACCOUNT with the actual service account email
      # Ensure this service account has permissions to access the secrets in Secret Manager
      #
      # SERVICE ACCOUNT FOR WORKLOAD IDENTITY:
      # 1. Create a Kubernetes Service Account (KSA) in the 'rabbitmq-qa' namespace (e.g., rabbitmq-ksa).
      # 2. Create a Google Service Account (GSA) with appropriate permissions
      #    (e.g., Artifact Registry Reader, Secret Manager Secret Accessor).
      # 3. Bind the KSA to the GSA using Workload Identity:
      #    gcloud iam service-accounts add-iam-policy-binding \
      #      --role roles/iam.workloadIdentityUser \
      #      --member "serviceAccount:YOUR_GCP_PROJECT.svc.id.goog[rabbitmq-qa/rabbitmq-ksa]" \
      #      YOUR_GSA_EMAIL
      # 4. Annotate the KSA:
      #    kubectl annotate serviceaccount rabbitmq-ksa \
      #      --namespace rabbitmq-qa \
      #      iam.gke.io/gcp-service-account=YOUR_GSA_EMAIL
      # 5. Uncomment and set the serviceAccountName below to your KSA name.
      serviceAccountName: <%= bindings["rabbitmq_ksa_name"] || "rabbitmq-ksa" %>

      securityContext:
        runAsUser: 999 # UID for rabbitmq user in the standard image
        runAsGroup: 999 # GID for rabbitmq user in the standard image
        fsGroup: 999    # Ensures the mounted volumes are writable by the rabbitmq group

      # If image pull secrets are needed from a private registry (and not using Workload Identity for GCR)
      # imagePullSecrets:
      # - name: my-image-pull-secret # Replace with your image pull secret name

      containers:
      - name: rabbitmq
        image: <%= bindings["rabbitmq_image_repository"] || "rabbitmq" %>:<%= bindings["rabbitmq_image_tag"] || "3.12-management" %> # Using a version with management plugin
        imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: "<%= bindings["rabbitmq_cpu_limit"] || "1" %>"
              memory: "<%= bindings["rabbitmq_memory_limit"] || "2Gi" %>"
            requests:
              cpu: "<%= bindings["rabbitmq_cpu_request"] || "500m" %>"
              memory: "<%= bindings["rabbitmq_memory_request"] || "1Gi" %>"
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
          runAsGroup: 999
          # For stricter security, if your RabbitMQ version/config supports it:
          # readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
            # Add specific capabilities if RabbitMQ truly needs them, e.g., NET_BIND_SERVICE if not running as root and binding to privileged ports (not the case here)
        ports:
        - name: amqp
          containerPort: 5672
        - name: management
          containerPort: 15672
        - name: prometheus # Port for Prometheus metrics if enabled
          containerPort: 15692
        # - name: epmd # Erlang Port Mapper Daemon - not directly needed if using K8S discovery
        #   containerPort: 4369
        # - name: cluster-rpc
        #   containerPort: 25672 # For inter-node and CLI tool communication

        livenessProbe:
          exec:
            command: ["rabbitmq-diagnostics", "status"]
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 15
        readinessProbe:
          exec:
            command: ["rabbitmq-diagnostics", "ping", "-q"]
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10

        env:
        - name: RABBITMQ_CONFIG_FILE
          value: "/etc/rabbitmq/rabbitmq.conf"
        - name: RABBITMQ_DEFINITIONS_FILE
          value: "/etc/rabbitmq/definitions.json"
        - name: RABBITMQ_ENABLED_PLUGINS_FILE
          value: "/etc/rabbitmq/enabled_plugins"
        # Used by the k8s peer discovery plugin
        - name: K8S_SERVICE_NAME
          value: "rabbitmq-headless" # Name of the headless service
        - name: K8S_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: RABBITMQ_ERLANG_COOKIE_FILE
          value: "/mnt/secrets-store/erlang_cookie"
        # Hostname needs to be fully qualified for clustering with k8s discovery if address_type=hostname
        # Forcing FQDN for hostname. This helps in consistent node naming for RabbitMQ.
        - name: RABBITMQ_NODENAME
          value: "rabbit@$(HOSTNAME).$(K8S_SERVICE_NAME).$(K8S_NAMESPACE).svc.cluster.local"
        # Example: Exposing default user/pass from secret (if not using definitions.json for user management)
        # - name: RABBITMQ_DEFAULT_USER
        #   valueFrom:
        #     secretKeyRef:
        #       name: rabbitmq-secret
        #       key: admin_username # Assuming you add this to your secret
        # - name: RABBITMQ_DEFAULT_PASS
        #   valueFrom:
        #     secretKeyRef:
        #       name: rabbitmq-secret
        #       key: admin_password # From rabbitmq-secret.yaml

        volumeMounts:
        - name: config-volume
          mountPath: /etc/rabbitmq
        - name: data
          mountPath: /var/lib/rabbitmq
          # subPath: if you want to put it in a subdirectory of the PVC
        - name: secrets-store-inline
          mountPath: "/mnt/secrets-store/erlang_cookie" # Mount path for the erlang cookie
          subPath: erlang_cookie # Mount only the erlang_cookie file
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: rabbitmq-config
          items:
          - key: definitions.json
            path: definitions.json
          - key: enabled_plugins
            path: enabled_plugins
        - name: secrets-store-inline
          csi:
            driver: secrets-store.csi.k8s.io
            readOnly: true
            volumeAttributes:
              secretProviderClass: "rabbitmq-gcp-secrets"
            # Optional: if you want to also create K8s secrets from the fetched secrets
            # nodePublishSecretRef:
            #   name: rabbitmq-csi-synced-secret # Only if syncSecret is enabled in SecretProviderClass

  # Volume Claim Templates for Persistent Storage
  # Each pod gets its own PersistentVolumeClaim
  volumeClaimTemplates:
  - metadata:
      name: data # Name must match the volumeMounts.name for data
      labels:
        app: rabbitmq
    spec:
      accessModes: [ "ReadWriteOnce" ] # Suitable for most cloud provider block storage
      resources:
        requests:
          storage: <%= bindings["rabbitmq_pvc_size"] || "10Gi" %> # Default to 10Gi if not specified
      # storageClassName: "standard" # Uncomment and specify if you need a specific storage class
